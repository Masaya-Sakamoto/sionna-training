{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "f6152793-27d8-44b1-94fc-27e932c99d77"
   },
   "source": [
    "# Introduction to Sionna RT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "d4a0c3a1-b7de-43d5-be41-7c0b8c7701d7"
   },
   "source": [
    "Ray tracing is a technique to simulate environment-specific and physically accurate channel realizations for a given scene and user position.\n",
    "Please see the [EM Primer](https://nvlabs.github.io/sionna/rt/em_primer.html) for further details on the theoretical background of ray tracing of wireless channels.\n",
    "\n",
    "Sionna RT is a open-source hardware-accelerated differentiable ray tracer for radio propagation modeling which is built on top of [Mitsuba 3](https://www.mitsuba-renderer.org/). Mitsuba 3 is a rendering system for forward and inverse light-transport simulation that makes use of the differentiable just-in-time compiler [Dr.Jit](https://drjit.readthedocs.io/en/latest/).\n",
    "\n",
    "Thanks to Dr.Jit's automatic gradient computation, gradients of functions of channel responses or radio maps with respect to most parameters of the ray tracing process, including material properties, antenna and scattering patterns, orientations, and positions of objects, can be efficiently computed and used in various gradient-based optimization problems.\n",
    "\n",
    "Sionna RT relies on Mitsuba 3 for the rendering and handling of scenes, e.g., its XML-file format.\n",
    "\n",
    "Scene files for Mitsuba 3 can be created, edited, and exported with the popular open-source 3D creation suite [Blender](https://www.blender.org/) and the [Mitsuba-Blender add-on](https://github.com/mitsuba-renderer/mitsuba-blender). One can rapdily create scenes from almost any place in the world using [OpenStreetMap](https://www.openstreetmap.org/) and the [Blender-OSM add-on](https://prochitecture.gumroad.com/l/blender-osm). In Sionna, scenes and radio propagation paths can be either rendered through the lens of configurable cameras via ray tracing or displayed with an integrated 3D viewer. For more detail on scene creation and rendering, we refer to [Sionna RT's API documentation](https://nvlabs.github.io/sionna/rt/api/rt.html) and the available [video tutorial](https://youtu.be/7xHLDxUaQ7c)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "7cccc6f7-1426-4c40-aab3-de040d9081b0"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "572e6856-2fbf-48c8-988d-fbb4f141f023"
   },
   "outputs": [],
   "source": [
    "# Import or install Sionna\n",
    "try:\n",
    "    import sionna.rt\n",
    "except ImportError as e:\n",
    "    import os\n",
    "    os.system(\"pip install sionna-rt\")\n",
    "    import sionna.rt\n",
    "\n",
    "# Other imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "no_preview = True # Toggle to False to use the preview widget\n",
    "\n",
    "# Import relevant components from Sionna RT\n",
    "from sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, Camera,\\\n",
    "                      PathSolver, RadioMapSolver, subcarrier_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "681f7bfe-70d2-47dd-9dd4-55248e06bbcf"
   },
   "source": [
    "## Loading and Visualizing Scenes\n",
    "\n",
    "Sionna RT can either load external scene files (in Mitsuba's XML file format) or it can load one of the [integrated scenes](https://nvlabs.github.io/sionna/rt/api/scene.html#examples).\n",
    "\n",
    "In this example, we load an example scene containing the area around the Frauenkirche in Munich, Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "4a2cb86d-90a2-4605-b21d-350325f7ab77"
   },
   "outputs": [],
   "source": [
    "# Load integrated scene\n",
    "scene = load_scene(sionna.rt.scene.munich) # Try also sionna.rt.scene.etoile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "21732fac-1c91-4972-9ed9-b4e78b691a76"
   },
   "source": [
    "To visualize the scene, we can use the `preview` function which opens an interactive preview of the scene.\n",
    "This only works in Jupyter notebooks.\n",
    "\n",
    "You can use the following controls:\n",
    "\n",
    "- Mouse left: Rotate\n",
    "- Scroll wheel: Zoom\n",
    "- Mouse right: Move\n",
    "\n",
    "Please note that only one preview instance per scene can be opened at the same time.\n",
    "However, multiple scenes can be loaded in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "7a274511-6ad1-41ad-b7f4-d64d32962f20"
   },
   "outputs": [],
   "source": [
    "if not no_preview:\n",
    "    scene.preview();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "d85222cd-d8a5-4812-8b2a-e6ca19f113f9"
   },
   "source": [
    "It is often convenient to choose a viewpoint in the 3D preview prior to rendering it as a high-quality image.\n",
    "The next cell uses the \"preview\" camera which corresponds to the viewpoint of the current preview image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "b07977fe-3311-45bc-983d-29748089cf14"
   },
   "outputs": [],
   "source": [
    "# Only availabe if a preview is open\n",
    "if not no_preview:\n",
    "    scene.render(camera=\"preview\", num_samples=512);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "32aa643e-e9cb-4391-9eab-9b799cda58ca"
   },
   "source": [
    "One can also render the image to a file as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "ce6fc5c8-531f-4dac-b580-055bb0c46f73"
   },
   "outputs": [],
   "source": [
    "# Only availabe if a preview is open\n",
    "if not no_preview:\n",
    "    scene.render_to_file(camera=\"preview\",\n",
    "                         filename=\"scene.png\",\n",
    "                         resolution=[650,500]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "d4238e55-3a5a-4bdf-96fa-5bb088b9c0b8"
   },
   "source": [
    "Instead of the preview camera, one can also specify dedicated cameras with different positions and `look_at` directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "b607fb4a-1a4b-4d70-8253-7474b3c21225",
    "outputId": "7a28588a-6862-4abc-cd01-317f80ca9336"
   },
   "outputs": [],
   "source": [
    "# Create new camera with different configuration\n",
    "my_cam = Camera(position=[-250,250,150], look_at=[-15,30,28])\n",
    "\n",
    "# Render scene with new camera*\n",
    "scene.render(camera=my_cam, resolution=[650, 500], num_samples=512); # Increase num_samples to increase image quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "75dbd273-2296-4e42-a86f-b29aeca097a9"
   },
   "source": [
    "## Inspecting SceneObjects and Editing of Scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "b0222c8c-cda8-46b4-a8f5-e2fbed9862b9"
   },
   "source": [
    "A scene consists of multiple [SceneObjects](https://nvlabs.github.io/sionna/rt/api/scene_object.html) which can be accessed in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a643b5e-85be-4d3d-b6b3-c664200e0f13",
    "outputId": "6cccd98b-1447-4d15-d84e-f419d148cf6e"
   },
   "outputs": [],
   "source": [
    "scene = load_scene(sionna.rt.scene.simple_street_canyon, merge_shapes=False)\n",
    "scene.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "392c11e3-56a4-4912-ac21-097e7d1baa3c"
   },
   "outputs": [],
   "source": [
    "floor = scene.get(\"floor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "e852feb4-f3e4-400f-92dd-95a9cfcbc896"
   },
   "source": [
    "SceneObjects can be transformed by the following properties and methods:\n",
    "- position\n",
    "- orientation\n",
    "- scaling\n",
    "- look_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd43d5d8-ccf0-4ea3-af97-aea24679bd8b",
    "outputId": "2517da81-1fa4-462d-da74-dd01f30a071f"
   },
   "outputs": [],
   "source": [
    "print(\"Position (x,y,z) [m]: \", floor.position)\n",
    "print(\"Orientation (alpha, beta, gamma) [rad]: \", floor.orientation)\n",
    "print(\"Scaling: \", floor.scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "80a2f171-42a5-4c87-97fc-2b3ba7715710"
   },
   "source": [
    "More details on these functionalities can be found in the [Tutorial on Loading and Editing of Scenes](https://nvlabs.github.io/sionna/rt/tutorials/Scene-Edit.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "8d4fd91d-910e-42fa-9c00-e8a597bfdf85"
   },
   "source": [
    "Every SceneObject has another important property, the `velocity` vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca34a580-2bb6-4bb1-bbee-9739f9698e3f",
    "outputId": "98488397-0b30-4d7b-fd8b-377ba6814b3c"
   },
   "outputs": [],
   "source": [
    "print(\"Velocity (x,y,z) [m/s]: \", floor.velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "e8935c6c-7955-49a2-9d2b-7e6f03db913f"
   },
   "source": [
    "This property is used during the ray tracing process to compute a Doppler shift for every propagation path. This information can then be used to synthetically compute time evolution of channel impulse responses. More details on this topic are provided in the [Tutorial on Mobility](https://nvlabs.github.io/sionna/rt/tutorials/Mobility.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "ef115c74-5fa1-4645-8a64-00305b6d6992"
   },
   "source": [
    "The last property of SceneObjects that we discuss here is the [RadioMaterial](https://nvlabs.github.io/sionna/rt/api/radio_materials.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cfd810c-c406-4a36-ac72-974c486b6d62",
    "outputId": "6ccdacec-7038-4101-f96f-dccf51cde58a"
   },
   "outputs": [],
   "source": [
    "floor.radio_material"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "a3e7666d-9b92-4e62-8ea7-baa368390ab0"
   },
   "source": [
    "The radio material determines how an object interacts with incident radio waves. To learn more about radio materials and how they can be modified, we invited you to have a look at the Developer Guide on [Understanding Radio Materials](https://nvlabs.github.io/sionna/rt/developer/dev_custom_radio_materials.html).\n",
    "\n",
    "Depending on the type of radio material, some of its properties might change as a function of the frequency of the incident radio wave:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fe9acf6-bcac-4bb2-9452-d4c30d3838bd",
    "outputId": "68cbf410-c1c5-4fd8-ac2b-6d66e4756b55"
   },
   "outputs": [],
   "source": [
    "scene.frequency = 28e9 # in Hz; implicitly updates RadioMaterials that implement frequency dependent properties\n",
    "floor.radio_material # Note that the conductivity (sigma) changes automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "af398b4b-9348-4c64-ac54-a41a52ee3b58"
   },
   "source": [
    "## Ray tracing of Propagation Paths\n",
    "\n",
    "Once a scene is loaded, we can place Transmitters and Receivers in it and compute propagation paths between them.\n",
    "All transmitters and all receivers are equipped with the same antenna arrays which are defined by the `scene` properties `scene.tx_array` and `scene.rx_array`, respectively. Antenna arrays are composed of multiple identical antennas. Antennas can have custom or pre-defined patterns and are either single- or dual-polarized. A scene can contain multiple transmitters and receivers as long as they have unique names.\n",
    "\n",
    "More details on antenna patterns can be found in the Developer Guide [Understanding Radio Materials](https://nvlabs.github.io/sionna/rt/developer/dev_custom_radio_materials.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "id": "cf3a897a-95e2-4f53-be14-228848fffdef"
   },
   "outputs": [],
   "source": [
    "scene = load_scene(sionna.rt.scene.munich, merge_shapes=True) # Merge shapes to speed-up computations\n",
    "\n",
    "# Configure antenna array for all transmitters\n",
    "scene.tx_array = PlanarArray(num_rows=1,\n",
    "                             num_cols=1,\n",
    "                             vertical_spacing=0.5,\n",
    "                             horizontal_spacing=0.5,\n",
    "                             pattern=\"tr38901\",\n",
    "                             polarization=\"V\")\n",
    "\n",
    "# Configure antenna array for all receivers\n",
    "scene.rx_array = PlanarArray(num_rows=1,\n",
    "                             num_cols=1,\n",
    "                             vertical_spacing=0.5,\n",
    "                             horizontal_spacing=0.5,\n",
    "                             pattern=\"dipole\",\n",
    "                             polarization=\"cross\")\n",
    "\n",
    "# Create transmitter\n",
    "tx = Transmitter(name=\"tx\",\n",
    "                 position=[8.5,21,27],\n",
    "                 display_radius=2)\n",
    "\n",
    "# Add transmitter instance to scene\n",
    "scene.add(tx)\n",
    "\n",
    "# Create a receiver\n",
    "rx = Receiver(name=\"rx\",\n",
    "              position=[45,90,1.5],\n",
    "              display_radius=2)\n",
    "\n",
    "# Add receiver instance to scene\n",
    "scene.add(rx)\n",
    "\n",
    "tx.look_at(rx) # Transmitter points towards receiver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "ac7499f1-a172-4e1e-a18d-8a4a470d1715"
   },
   "source": [
    "Propagation paths are computed with the help of a [PathSolver](https://nvlabs.github.io/sionna/rt/api/paths_solvers.html).\n",
    "The next cell shows how such a path solver is instantiated and used.\n",
    "\n",
    "The parameter `max_depth` determines the maximum number of interactions between a ray and a scene objects.\n",
    "For example, with a `max_depth` of zero, only LoS paths are considered. For a `max_depth` of one, LoS as well as first-order reflections of refractions are considered.  When the argument `synthetic_array` is set to `False`, antenna arrays are explicitly modeled by finding paths between any pair of transmitting and receiving antennas in the scene. Otherwise, arrays are represented by a single antenna located in the center of the array.\n",
    "Phase shifts related to the relative antenna positions will then be applied based on a plane-wave assumption when the channel impulse responses are computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "661d1360-793a-4492-b6da-c2a7e1705003"
   },
   "outputs": [],
   "source": [
    "# Instantiate a path solver\n",
    "# The same path solver can be used with multiple scenes\n",
    "p_solver  = PathSolver()\n",
    "\n",
    "# Compute propagation paths\n",
    "paths = p_solver(scene=scene,\n",
    "                 max_depth=5,\n",
    "                 los=True,\n",
    "                 specular_reflection=True,\n",
    "                 diffuse_reflection=False,\n",
    "                 refraction=True,\n",
    "                 synthetic_array=False,\n",
    "                 seed=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "id": "d8eace50-6b26-4d33-89bc-c3df5c1b3fee"
   },
   "source": [
    "The [Paths](https://nvlabs.github.io/sionna/rt/paths.html) object contains all paths that have been found between transmitters and receivers.\n",
    "In principle, the existence of each path is determininistic for a given position and environment. Please note that due to the stochastic nature of the *shoot-and-bounce* algorithm, different runs of the path solver can lead to different paths that are found. Most importantly, diffusely reflected paths are obtained through random sampling of directions after each interaction with a scene object. You can provide the `seed` argument to the solver to ensure reproducibility.\n",
    "\n",
    "Let us now visualize the found paths in the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "953b8509-3a34-40af-aea0-3615cfa073c0",
    "outputId": "43e65d18-0489-4cde-f2ec-eefba2724c50"
   },
   "outputs": [],
   "source": [
    "if no_preview:\n",
    "    scene.render(camera=my_cam, paths=paths, clip_at=20);\n",
    "else:\n",
    "    scene.preview(paths=paths, clip_at=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "id": "14830d56-b8ba-4b19-aaeb-118534497852"
   },
   "source": [
    "The Paths object contains detailed information about every found path and allows us to generate channel impulse responses and apply Doppler shifts for the simulation of time evolution. For a detailed description, we refer to the developer guide [Understanding the Paths Object](https://nvlabs.github.io/sionna/rt/developer/dev_understanding_paths.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {
    "id": "a624ff7d-863a-44c1-9d98-4885637cb8cc"
   },
   "source": [
    "## From Paths to Channel Impulse and Frequency Responses\n",
    "\n",
    "Once paths are computed, they can be transformed into a baseband-equivalent channel impulse response (CIR) via [Paths.cir()](https://nvlabs.github.io/sionna/rt/api/paths.html#sionna.rt.Paths.cir), into a discrete complex baseband-equivalent channel impulse response via [Paths.taps()](https://nvlabs.github.io/sionna/rt/api/paths.html#sionna.rt.Paths.taps), or into a channel frequency response (CFR) via\n",
    "[Paths.cfr()](https://nvlabs.github.io/sionna/rt/api/paths.html#sionna.rt.Paths.cfr). These class methods can simulate time evolution of the channel based on the computed Doppler shifts (see [Paths.doppler](https://nvlabs.github.io/sionna/rt/api/paths.html#sionna.rt.Paths.doppler)).\n",
    "\n",
    "Let us first derive and visualize the baseband-equivalent channel impulse response from the paths computed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6e3b6092-7d05-4ba5-b5fa-09647e3c3a9e",
    "outputId": "8b3ec3aa-8f32-4e0b-d58e-cd50828c91f6"
   },
   "outputs": [],
   "source": [
    "a, tau = paths.cir(normalize_delays=True, out_type=\"numpy\")\n",
    "\n",
    "# Shape: [num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]\n",
    "print(\"Shape of a: \", a.shape)\n",
    "\n",
    "# Shape: [num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths]\n",
    "print(\"Shape of tau: \", tau.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "id": "f4bcab36-64e5-4355-ad93-d40b2c196c00"
   },
   "source": [
    "The `out_type` argument can be used to convert the CIR into tensors from different frameworks, such as [Dr.Jit](https://drjit.readthedocs.io/en/latest/reference.html) (\"drjit\"), [Numpy](https://numpy.org) (\"numpy\"),\n",
    "            [Jax](https://jax.readthedocs.io/en/latest/index.html) (\"jax\"),\n",
    "            [TensorFlow](https://www.tensorflow.org) (\"tf\"),\n",
    "            and [PyTorch](https://pytorch.org) (\"torch\"). Please see the developer guide [Compatibility with other Frameworks](https://nvlabs.github.io/sionna/rt/developer/dev_compat_frameworks.html) for more information on the interoperability of Sionna RT with other array frameworks, including the propagation of gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "9fbcd26d-6b73-4571-9a70-378e73a1ef96",
    "outputId": "cdcc6312-1964-4b93-cf17-e2edf4d0d549"
   },
   "outputs": [],
   "source": [
    "t = tau[0,0,0,0,:]/1e-9 # Scale to ns\n",
    "a_abs = np.abs(a)[0,0,0,0,:,0]\n",
    "a_max = np.max(a_abs)\n",
    "\n",
    "# And plot the CIR\n",
    "plt.figure()\n",
    "plt.title(\"Channel impulse response\")\n",
    "plt.stem(t, a_abs)\n",
    "plt.xlabel(r\"$\\tau$ [ns]\")\n",
    "plt.ylabel(r\"$|a|$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {
    "id": "ef5a9bc2-b183-4fcd-8788-2c77136b32ac"
   },
   "source": [
    "Note that the delay of the first arriving path is by default normalized to zero. This behavior can be changed by setting the argument ``normalize_delays`` to `True`.\n",
    "\n",
    "We can obtain the channel frequency response in a similar manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "8ecf07e7-7aae-4dbc-8b96-568cb9e99cf5",
    "outputId": "9ad37af3-68f7-4253-d5b5-fdba0ad89d2e"
   },
   "outputs": [],
   "source": [
    "# OFDM system parameters\n",
    "num_subcarriers = 1024\n",
    "subcarrier_spacing=30e3\n",
    "\n",
    "# Compute frequencies of subcarriers relative to the carrier frequency\n",
    "frequencies = subcarrier_frequencies(num_subcarriers, subcarrier_spacing)\n",
    "\n",
    "# Compute channel frequency response\n",
    "h_freq = paths.cfr(frequencies=frequencies,\n",
    "                   normalize=True, # Normalize energy\n",
    "                   normalize_delays=True,\n",
    "                   out_type=\"numpy\")\n",
    "\n",
    "# Shape: [num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps, num_subcarriers]\n",
    "print(\"Shape of h_freq: \", h_freq.shape)\n",
    "\n",
    "# Plot absolute value\n",
    "plt.figure()\n",
    "plt.plot(np.abs(h_freq)[0,0,0,0,0,:]);\n",
    "plt.xlabel(\"Subcarrier index\");\n",
    "plt.ylabel(r\"|$h_\\text{freq}$|\");\n",
    "plt.title(\"Channel frequency response\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "id": "b39077ba-bd9f-47b2-8abf-06e56bd074ad"
   },
   "source": [
    "For link-level simulations in the time-domain, we often require the discrete baseband-equivalent channel impulse response or simply the channel taps.\n",
    "These are obtained by sampling the ideally low-pass filtered channel impulse response at the desired sampling frequency. By default, it is assumed that sampling is performed at the Nyquist rate.\n",
    "\n",
    "As the underlying sinc filter has an infinitely long response, the channel taps need to be truncated at a minimum and maximum value, i.e., `l_min` and `l_max`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "id": "ba6a1e34-b75f-4ff1-9b61-87c518a2ad69",
    "outputId": "7b10fea6-3a2f-4976-c34e-ef144545ae27"
   },
   "outputs": [],
   "source": [
    "taps = paths.taps(bandwidth=100e6, # Bandwidth to which the channel is low-pass filtered\n",
    "                  l_min=-6,        # Smallest time lag\n",
    "                  l_max=100,       # Largest time lag\n",
    "                  sampling_frequency=None, # Sampling at Nyquist rate, i.e., 1/bandwidth\n",
    "                  normalize=True,  # Normalize energy\n",
    "                  normalize_delays=True,\n",
    "                  out_type=\"numpy\")\n",
    "print(\"Shape of taps: \", taps.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.stem(np.arange(-6, 101), np.abs(taps)[0,0,0,0,0]);\n",
    "plt.xlabel(r\"Tap index $\\ell$\");\n",
    "plt.ylabel(r\"|$h[\\ell]|$\");\n",
    "plt.title(\"Discrete channel taps\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "id": "8b48c405-b590-4630-9e34-e26a07902c34"
   },
   "source": [
    "Every radio device and scene object has a velocity vector associated with it. These are used to compute path-specific Doppler shifts that enable the simulation of mobility. More details can be found in the [Tutorial on Mobility](https://nvlabs.github.io/sionna/rt/tutorials/Mobility.html).\n",
    "\n",
    "We will now assign a non-zero velocity vector to the transmitter, recompute the propagation paths, and compute a time-varying channel impulse reponse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "id": "6a31f452-29fe-4b13-9886-baa385458eca",
    "outputId": "493d0ca4-a9da-4475-febf-073400bb6ce5"
   },
   "outputs": [],
   "source": [
    "scene.get(\"tx\").velocity = [10, 0, 0]\n",
    "\n",
    "# Recompute propagation paths\n",
    "paths_mob = p_solver(scene=scene,\n",
    "                     max_depth=5,\n",
    "                     los=True,\n",
    "                     specular_reflection=True,\n",
    "                     diffuse_reflection=False,\n",
    "                     refraction=True,\n",
    "                     synthetic_array=True,\n",
    "                     seed=41)\n",
    "\n",
    "# Compute CIR with time-evolution\n",
    "num_time_steps=100\n",
    "sampling_frequency = 1e4\n",
    "a_mob, _ = paths_mob.cir(sampling_frequency=sampling_frequency,\n",
    "                         num_time_steps=num_time_steps,\n",
    "                         out_type=\"numpy\")\n",
    "\n",
    "# Inspect time-evolution of a single path coefficient\n",
    "plt.figure()\n",
    "plt.plot(np.arange(num_time_steps)/sampling_frequency*1000,\n",
    "         a_mob[0,0,0,0,0].real);\n",
    "plt.xlabel(\"Time [ms]\");\n",
    "plt.ylabel(r\"$\\Re\\{a_0(t) \\}$\");\n",
    "plt.title(\"Time-evolution of a path coefficient\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "id": "cb4453d9-25de-4f92-8747-29a389bf55e7"
   },
   "source": [
    "## Radio Maps\n",
    "\n",
    "Sionna RT can compute radio maps for all transmitters in a scene. A [RadioMap](https://nvlabs.github.io/sionna/rt/api/radio_maps.html) assigns a metric, such as path gain, received signal strength (RSS), or signal-to-interference-plus-noise ratio (SINR), for a specific transmitter to every point on a plane. In other words, for a given transmitter, it associates every point on a surface with the channel gain, RSS, or SINR, that a receiver with a specific orientation would observe at this point.\n",
    "\n",
    "Like the computation of propagation paths requires a [PathSolver](https://nvlabs.github.io/sionna/rt/api/paths_solvers.html), the computation of radio maps requires a [RadioMapSolver](https://nvlabs.github.io/sionna/rt/api/radio_map_solvers.html). The following code snippet shows how a radio map can be computed and displayed.\n",
    "\n",
    "More information about radio maps can be found in the detailed [Tutorial on Radio Maps](https://nvlabs.github.io/sionna/rt/tutorials/Radio-Maps.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "id": "8221ded8-6c50-482b-9d76-bcb42651e999"
   },
   "outputs": [],
   "source": [
    "rm_solver = RadioMapSolver()\n",
    "\n",
    "rm = rm_solver(scene=scene,\n",
    "               max_depth=5,\n",
    "               cell_size=[1,1],\n",
    "               samples_per_tx=10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {
    "id": "5c47e2ab-a157-4f8d-81fc-632580e4726b",
    "outputId": "e46612e2-2aec-45f0-cd6f-bb8b9b00a626"
   },
   "outputs": [],
   "source": [
    "if no_preview:\n",
    "    scene.render(camera=my_cam, radio_map=rm);\n",
    "else:\n",
    "    scene.preview(radio_map=rm);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {
    "id": "e4658241-9685-4d4f-a870-0590aa8608b8"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you have learned the basics of Sionna RT. You now know how paths can be found in complex environments\n",
    "and how the CIR, CFR, and taps can be derived from them. You have also learned how radio maps can be created.\n",
    "\n",
    "There is one key feature of Sionna RT that was not discussed in this notebook: Automatic gradient computation.\n",
    "Like most components of Sionna, also Sionna RT is differentiable with respect to most parameters, such as radio materials, scattering and atenna patterns, transmitter and receiver orientations, array geometries, positions, etc.\n",
    "\n",
    "Please have a look at the [API documentation](https://nvlabs.github.io/sionna/rt/api/rt.html) of the various components and the other available [Tutorials](https://nvlabs.github.io/sionna/rt/tutorials.html) and [Developer Guides](https://nvlabs.github.io/sionna/rt/developer/developer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sionna-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
